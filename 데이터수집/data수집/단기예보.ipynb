{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "439d52cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¡ ë‹¨ê¸°ì˜ˆë³´ ìˆ˜ì§‘ ì‹œì‘\n",
      "âŒ ìˆ˜ì§‘ ì‹¤íŒ¨: HTTPSConnectionPool(host='apis.data.go.kr', port=443): Max retries exceeded with url: /1360000/VilageFcstInfoService_2.0/getVilageFcst?serviceKey=prE5nprnhB9u6l%2BsEZ7eyTE1s3G8HsLeMqpdV9c4RhUAGp03obu1bxAzYTcnbg4x2%2B4y8NbOTC0Yw5S0Y4hGIA%3D%3D&numOfRows=1000&pageNo=1&dataType=JSON&base_date=20250713&base_time=2300&nx=60&ny=127 (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_ILLEGAL_PARAMETER] sslv3 alert illegal parameter (_ssl.c:1017)')))\n",
      "â„¹ï¸ ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 1. í™˜ê²½ë³€ìˆ˜ ì—ì„œ apií‚¤ ë¡œë”©\n",
    "load_dotenv()\n",
    "SERVICE_KEY = os.getenv(\"OPENWEATHER_API_KEY\")\n",
    "\n",
    "# 2. ì„¤ì •ê°’\n",
    "CSV_FILE = \"short_forecast.csv\"\n",
    "NX, NY = 60, 127  # ì„œìš¸ (ê²©ì ìœ„ì¹˜)\n",
    "API_URL = \"https://apis.data.go.kr/1360000/VilageFcstInfoService_2.0/getVilageFcst\"\n",
    "\n",
    "# 3. ê¸°ì¡´ ë‹¨ê¸°ì˜ˆë³´ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "def load_existing_forecast():\n",
    "    if os.path.exists(CSV_FILE):\n",
    "        return pd.read_csv(CSV_FILE)\n",
    "    return pd.DataFrame()\n",
    "\n",
    "# 4. ë‹¨ê¸°ì˜ˆë³´ ìˆ˜ì§‘ (í•˜ë£¨ ì „ base_time ê³„ì‚° í¬í•¨)\n",
    "def get_yesterday_base_time():\n",
    "    base_times = ['2300', '2000', '1700', '1400', '1100', '0800', '0500', '0200']\n",
    "    base_time = base_times[0]\n",
    "    base_date = (datetime.now() - timedelta(days=1)).strftime(\"%Y%m%d\")\n",
    "    return base_date, base_time\n",
    "\n",
    "def fetch_short_forecast():\n",
    "    base_date, base_time = get_yesterday_base_time()\n",
    "\n",
    "    params = {\n",
    "        \"serviceKey\": SERVICE_KEY,\n",
    "        \"numOfRows\": \"1000\",\n",
    "        \"pageNo\": \"1\",\n",
    "        \"dataType\": \"JSON\",\n",
    "        \"base_date\": base_date,\n",
    "        \"base_time\": base_time,\n",
    "        \"nx\": NX,\n",
    "        \"ny\": NY\n",
    "    }\n",
    "\n",
    "    print(\"ğŸ“¡ ë‹¨ê¸°ì˜ˆë³´ ìˆ˜ì§‘ ì‹œì‘\")\n",
    "    try:\n",
    "        response = requests.get(API_URL, params=params, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        items = data.get(\"response\", {}).get(\"body\", {}).get(\"items\", {}).get(\"item\", [])\n",
    "        print(f\"âœ… {len(items)}ê±´ ìˆ˜ì§‘ ì™„ë£Œ\")\n",
    "        return items\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}\")\n",
    "        return []\n",
    "\n",
    "# 5. ìƒˆë¡œìš´ ì˜ˆë³´ë§Œ ì €ì¥\n",
    "def save_incremental_forecast(items):\n",
    "    if not items:\n",
    "        print(\"â„¹ï¸ ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "\n",
    "    df_new = pd.DataFrame(items)\n",
    "    df_old = load_existing_forecast()\n",
    "\n",
    "    if not df_old.empty:\n",
    "        merge_keys = [\"fcstDate\", \"fcstTime\", \"category\", \"nx\", \"ny\"]\n",
    "        df_merge = pd.merge(df_new, df_old, on=merge_keys, how=\"left\", indicator=True)\n",
    "        df_filtered = df_merge[df_merge[\"_merge\"] == \"left_only\"][df_new.columns]\n",
    "        print(f\"ğŸ†• ìƒˆë¡œìš´ ì˜ˆë³´ {len(df_filtered)}ê±´ ì €ì¥ë¨\")\n",
    "    else:\n",
    "        df_filtered = df_new\n",
    "        print(f\"ğŸ“ ì²« ì €ì¥: {len(df_filtered)}ê±´\")\n",
    "\n",
    "    write_header = not os.path.exists(CSV_FILE)\n",
    "    df_filtered.to_csv(CSV_FILE, mode='a', index=False, header=write_header)\n",
    "    print(f\"ğŸ“… {datetime.now().strftime('%Y-%m-%d')} ì €ì¥ ì™„ë£Œ\")\n",
    "\n",
    "# ì‹¤í–‰\n",
    "if __name__ == \"__main__\":\n",
    "    items = fetch_short_forecast()\n",
    "    save_incremental_forecast(items)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03e52e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-dl-nlp",
   "language": "python",
   "name": "ml-dl-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
